import streamlit as st
import pandas as pd
import numpy as np

# --- æ ¸å¿ƒç­–ç•¥ï¼šè‚¡æ³°æµ SOP åš´æ ¼ç¯©é¸å™¨ (å·²ç§»é™¤æ›å–®/ç„¡è³£å–®æª¢æŸ¥) ---
class GuTaiSOPAnalyzer:
    def __init__(self):
        pass

    def analyze(self, df):
        # 1. æ¬„ä½å°æ‡‰èˆ‡è³‡æ–™æ¸…æ´—
        target_map = {
            'æ¬Šè­‰åç¨±': ['æ¬Šè­‰åç¨±'],
            'æ¬Šè­‰ä»£ç¢¼': ['æ¬Šè­‰ä»£ç¢¼'],
            'æ¨™çš„åç¨±': ['æ¨™çš„åç¨±', 'æ¨™çš„è­‰åˆ¸'],
            'æ¨™çš„ä»£ç¢¼': ['æ¨™çš„ä»£ç¢¼'],
            'æ¨™çš„åƒ¹æ ¼': ['æ¨™çš„åƒ¹æ ¼', 'æ¨™çš„è‚¡åƒ¹', 'æ¨™çš„æ”¶ç›¤'],
            'è²·åƒ¹': ['æ¬Šè­‰è²·åƒ¹', 'æœ€ä½³è²·åƒ¹', 'è²·åƒ¹'],
            'è³£åƒ¹': ['æ¬Šè­‰è³£åƒ¹', 'æœ€ä½³è³£åƒ¹', 'è³£åƒ¹'],
            'è²·é‡': ['è²·é€²æ¨è¨ˆé‡', 'è²·å¼µ', 'æœ€ä½³è²·é‡'],
            'è³£é‡': ['è³£å‡ºæ¨è¨ˆé‡', 'è³£å¼µ', 'æœ€ä½³è³£é‡'],
            'å±¥ç´„åƒ¹': ['å±¥ç´„åƒ¹', 'åŸ·è¡Œåƒ¹'],
            'å‰©é¤˜å¤©æ•¸': ['å‰©é¤˜å¤©æ•¸', 'è·åˆ°æœŸæ—¥', 'å¤©æ•¸'],
            'æµé€šå¼µæ•¸': ['æµé€šåœ¨å¤–ä¼°è¨ˆå¼µæ•¸', 'æµé€šåœ¨å¤–å¼µæ•¸', 'æœ€æ–°æµé€šåœ¨å¤–å¼µæ•¸', 'å¤–æµå¼µæ•¸'],
            'ç™¼è¡Œå¼µæ•¸': ['ç™¼è¡Œé‡', 'ç™¼è¡Œå¼µæ•¸'],
            'éš±å«æ³¢å‹•ç‡': ['éš±å«æ³¢å‹•ç‡', 'BIV', 'å§”è²·éš±å«æ³¢å‹•ç‡', 'è²·é€²IV'],
            'æ­·å²æ³¢å‹•ç‡': ['æ¨™çš„20æ—¥æ³¢å‹•ç‡', 'æ­·å²æ³¢å‹•ç‡', 'SV20', '20æ—¥æ³¢å‹•ç‡'],
            'Delta': ['DELTA', 'Delta', 'å°æ²–å€¼'],
            'Gamma': ['GAMMA', 'Gamma'],
            'Theta': ['THETA', 'Theta']
        }

        df_clean = pd.DataFrame()
        
        # é–å®šæ¬„ä½
        for target, keywords in target_map.items():
            best_match = None
            for kw in keywords:
                matches = [c for c in df.columns if kw in c]
                if matches:
                    best_match = matches[0]
                    break
            
            if best_match:
                df_clean[target] = df[best_match]
            else:
                if target in ['æ¬Šè­‰åç¨±', 'æ¬Šè­‰ä»£ç¢¼', 'æ¨™çš„åç¨±']:
                    df_clean[target] = ''
                else:
                    df_clean[target] = 0

        # è½‰æ•¸å€¼
        numeric_cols = ['è²·åƒ¹', 'è³£åƒ¹', 'è²·é‡', 'è³£é‡', 'å±¥ç´„åƒ¹', 'å‰©é¤˜å¤©æ•¸', 'æ¨™çš„åƒ¹æ ¼', 
                        'æµé€šå¼µæ•¸', 'ç™¼è¡Œå¼µæ•¸', 'éš±å«æ³¢å‹•ç‡', 'æ­·å²æ³¢å‹•ç‡', 'Delta', 'Gamma', 'Theta']
        
        for col in numeric_cols:
            if col in df_clean.columns:
                df_clean[col] = df_clean[col].astype(str).str.replace('%', '', regex=False).str.replace(',', '', regex=False)
                df_clean[col] = pd.to_numeric(df_clean[col], errors='coerce').fillna(0)

        # 2. è¨ˆç®—é—œéµæŒ‡æ¨™
        
        # A. åƒ¹å·®æ¯” (Spread)
        df_clean['åƒ¹å·®æ¯”'] = np.where(df_clean['è²·åƒ¹'] > 0, 
                                     (df_clean['è³£åƒ¹'] - df_clean['è²·åƒ¹']) / df_clean['è²·åƒ¹'] * 100, 
                                     999)
        
        # B. æµé€šæ¯”
        df_clean['æµé€šæ¯”'] = 0.0
        mask_issue = df_clean['ç™¼è¡Œå¼µæ•¸'] > 0
        df_clean.loc[mask_issue, 'æµé€šæ¯”'] = (df_clean.loc[mask_issue, 'æµé€šå¼µæ•¸'] / df_clean.loc[mask_issue, 'ç™¼è¡Œå¼µæ•¸']) * 100
        
        # C. æ³¢å‹•ç‡æ ¡æ­£
        mask_iv = df_clean['éš±å«æ³¢å‹•ç‡'] > 2
        df_clean.loc[mask_iv, 'éš±å«æ³¢å‹•ç‡'] = df_clean.loc[mask_iv, 'éš±å«æ³¢å‹•ç‡'] / 100
        mask_hv = df_clean['æ­·å²æ³¢å‹•ç‡'] > 2
        df_clean.loc[mask_hv, 'æ­·å²æ³¢å‹•ç‡'] = df_clean.loc[mask_hv, 'æ­·å²æ³¢å‹•ç‡'] / 100

        # D. åƒ¹å…§å¤–ç¨‹åº¦
        df_clean['åƒ¹å…§å¤–'] = (df_clean['æ¨™çš„åƒ¹æ ¼'] - df_clean['å±¥ç´„åƒ¹']) / df_clean['å±¥ç´„åƒ¹']


        # 3. è‚¡æ³°æµ SOP åš´æ ¼ç¯©é¸é‚è¼¯
        df_clean['SOPç‹€æ…‹'] = 'é€šé'
        df_clean['æœªé€šéåŸå› '] = ''
        
        def add_fail_reason(mask, reason):
            df_clean.loc[mask, 'æœªé€šéåŸå› '] = np.where(
                df_clean.loc[mask, 'æœªé€šéåŸå› '] == '',
                reason,
                df_clean.loc[mask, 'æœªé€šéåŸå› '] + ', ' + reason
            )
            df_clean.loc[mask, 'SOPç‹€æ…‹'] = 'å‰”é™¤'

        # --- è¦å‰‡ 1: å‰©é¤˜å¤©æ•¸ ---
        add_fail_reason(df_clean['å‰©é¤˜å¤©æ•¸'] < 60, 'å¤©æ•¸éçŸ­')
        
        # --- è¦å‰‡ 2: åƒ¹å…§å¤–èˆ‡ Delta ---
        has_delta = df_clean['Delta'].abs().sum() > 0
        if has_delta:
            abs_delta = df_clean['Delta'].abs()
            add_fail_reason((abs_delta < 0.35) | (abs_delta > 0.65), 'Deltaä¸ä½³')
        else:
            sweet_zone = (df_clean['åƒ¹å…§å¤–'] >= -0.15) & (df_clean['åƒ¹å…§å¤–'] <= 0.05)
            add_fail_reason(~sweet_zone, 'éé»ƒé‡‘å€é–“')

        # --- è¦å‰‡ 3: æµé€šæ¯” ---
        add_fail_reason(df_clean['æµé€šæ¯”'] > 80, 'é«˜æµé€šåœ°é›·')
        
        # --- è¦å‰‡ 4: åƒ¹å·®èˆ‡é€ å¸‚ (å·²ç§»é™¤ ç„¡è³£å–® & æ›å–®ä¸è¶³) ---
        # åƒ…ä¿ç•™åƒ¹å·®æ¯”éå¤§çš„æª¢æŸ¥
        add_fail_reason(df_clean['åƒ¹å·®æ¯”'] > 2.5, 'åƒ¹å·®éå¤§')
        # [å·²ç§»é™¤] add_fail_reason(df_clean['è³£åƒ¹'] == 0, 'ç„¡è³£å–®')
        # [å·²ç§»é™¤] add_fail_reason((df_clean['è²·é‡']<5) | (df_clean['è³£é‡']<5), 'æ›å–®ä¸è¶³')

        # --- è¦å‰‡ 5: éš±æ³¢é™·é˜± ---
        has_vol = (df_clean['æ­·å²æ³¢å‹•ç‡'] > 0) & (df_clean['éš±å«æ³¢å‹•ç‡'] > 0)
        is_expensive = has_vol & (df_clean['éš±å«æ³¢å‹•ç‡'] > (df_clean['æ­·å²æ³¢å‹•ç‡'] + 0.08)) 
        add_fail_reason(is_expensive, 'éš±æ³¢å¤ªè²´')

        # 4. æ’åº
        df_clean['æ’åºæ¬Šé‡'] = df_clean['åƒ¹å·®æ¯”']
        df_clean.loc[df_clean['SOPç‹€æ…‹'] == 'å‰”é™¤', 'æ’åºæ¬Šé‡'] += 1000
        
        return df_clean.sort_values(by='æ’åºæ¬Šé‡'), None

# --- æª”æ¡ˆè®€å– ---
def load_data_robust(file):
    filename = file.name.lower()
    try:
        if filename.endswith(('.xls', '.xlsx')):
            df_raw = pd.read_excel(file, header=None)
        else:
            try:
                df_raw = pd.read_csv(file, header=None, encoding='utf-8-sig')
            except:
                file.seek(0)
                df_raw = pd.read_csv(file, header=None, encoding='big5')
    except Exception as e:
        return None, f"æª”æ¡ˆè®€å–å¤±æ•—: {e}"

    # æ‰¾æ¨™é¡Œ
    header_idx = -1
    for i, row in df_raw.head(20).iterrows():
        row_str = " ".join(row.astype(str).values)
        if 'ä»£ç¢¼' in row_str and 'åç¨±' in row_str:
            header_idx = i
            break
    
    if header_idx == -1: return None, "æ‰¾ä¸åˆ°æ¨™é¡Œåˆ—"

    # é›™å±¤æ¨™é¡Œåˆä½µ
    new_columns = []
    if header_idx > 0:
        row_upper = df_raw.iloc[header_idx - 1].fillna('').astype(str)
        row_lower = df_raw.iloc[header_idx].fillna('').astype(str)
        if 'æ¨™çš„' in row_upper.values or 'æ¬Šè­‰' in row_upper.values:
            for up, low in zip(row_upper, row_lower):
                up, low = up.strip(), low.strip()
                new_columns.append(f"{up}{low}" if up and up!=low else low)
        else:
            new_columns = row_lower.tolist()
    else:
        new_columns = df_raw.iloc[header_idx].fillna('').astype(str).tolist()

    # é™¤é‡
    seen = {}
    deduped = []
    for col in new_columns:
        col = col.replace(' ', '').replace('\n', '')
        if col in seen: seen[col] += 1; deduped.append(f"{col}_{seen[col]}")
        else: seen[col] = 0; deduped.append(col)

    df = df_raw.iloc[header_idx + 1:].copy()
    df.columns = deduped
    return df, None

# --- ç¶²é ä»‹é¢ ---
st.set_page_config(page_title="è‚¡æ³°æµæ¬Šè­‰SOP", layout="wide")

st.title("ğŸ›¡ï¸ è‚¡æ³°æµ-æ¬Šè­‰ SOP åš´æ ¼ç¯©é¸å™¨")
st.markdown("""
æœ¬å·¥å…·ä¾ç…§ **ã€Œè‚¡æ³°æµ SOP è¡¨æ ¼ã€** é€²è¡Œåš´æ ¼æŠŠé—œã€‚
- **âœ… åš´é¸å€**ï¼šç¬¦åˆ Delta 0.4~0.6ã€å¤©æ•¸>60ã€ä½æµé€šã€ä½åƒ¹å·®ã€‚
- **âŒ å‰”é™¤å€**ï¼šé•åè¦å‰‡è€…ç›´æ¥å‰”é™¤ (å·²æ”¾å¯¬æ›å–®é‡æª¢æŸ¥)ã€‚
""")

uploaded_file = st.file_uploader("ğŸ“‚ ä¸Šå‚³æ¬Šè­‰å ±è¡¨ (Excel/CSV)", type=['csv', 'xls', 'xlsx'])

if uploaded_file is not None:
    df, error = load_data_robust(uploaded_file)
    
    if error:
        st.error(error)
    else:
        # æ¨™çš„é¸æ“‡
        target_col = next((c for c in df.columns if 'æ¨™çš„åç¨±' in c), None)
        if not target_col: target_col = next((c for c in df.columns if 'æ¨™çš„ä»£ç¢¼' in c), None)

        if not target_col:
            st.error("âŒ æ‰¾ä¸åˆ°æ¨™çš„åç¨±/ä»£ç¢¼æ¬„ä½")
        else:
            with st.sidebar:
                st.header("1ï¸âƒ£ æ¨™çš„ç¯©é¸")
                df[target_col] = df[target_col].astype(str).str.strip()
                stock_list = sorted([x for x in df[target_col].unique() if x.lower() != 'nan' and x != ''])
                selected_stock = st.selectbox("æœå°‹æ¨™çš„:", stock_list)
                
                df_filtered = df[df[target_col] == selected_stock].copy()
                
                current_price = 0
                price_col = next((c for c in df_filtered.columns if 'æ¨™çš„åƒ¹æ ¼' in c), None)
                if price_col:
                    try:
                        current_price = pd.to_numeric(df_filtered[price_col], errors='coerce').iloc[0]
                        st.metric("æ¯è‚¡åƒ¹æ ¼", f"{current_price:.2f}")
                    except: pass
                
                st.markdown("---")
                st.header("ğŸ’° è³‡é‡‘æ§ç®¡")
                total_capital = st.number_input("ç¸½è³‡é‡‘ (è¬)", value=100, step=10)
                st.info(f"æ¬Šè­‰å»ºè­°ä¸Šé™ (15%)ï¼š**{total_capital * 0.15:.1f} è¬**")

            # åŸ·è¡Œåˆ†æ
            if not df_filtered.empty:
                analyzer = GuTaiSOPAnalyzer()
                result_df, err = analyzer.analyze(df_filtered)
                
                if err:
                    st.error(err)
                else:
                    cols = ['æ¬Šè­‰åç¨±', 'æœªé€šéåŸå› ', 'Delta', 'å‰©é¤˜å¤©æ•¸', 'åƒ¹å·®æ¯”', 'æµé€šæ¯”', 
                            'è²·åƒ¹', 'è³£åƒ¹', 'éš±å«æ³¢å‹•ç‡', 'æ­·å²æ³¢å‹•ç‡', 'Gamma']
                    
                    fmt = {
                        'Delta': '{:.2f}', 'Gamma': '{:.3f}', 
                        'åƒ¹å·®æ¯”': '{:.2f}%', 'æµé€šæ¯”': '{:.1f}%',
                        'éš±å«æ³¢å‹•ç‡': '{:.2f}', 'æ­·å²æ³¢å‹•ç‡': '{:.2f}', 
                        'è²·åƒ¹': '{:.2f}', 'è³£åƒ¹': '{:.2f}'
                    }

                    tab1, tab2 = st.tabs(["âœ… è‚¡æ³°åš´é¸", "âŒ å‰”é™¤å€"])
                    
                    with tab1:
                        good = result_df[result_df['SOPç‹€æ…‹'] == 'é€šé']
                        st.markdown(f"### ç¬¦åˆæ¨™æº–ï¼š{len(good)} æª”")
                        if not good.empty:
                            clean_cols = [c for c in cols if c != 'æœªé€šéåŸå› ']
                            st.dataframe(good[clean_cols].style.format(fmt))
                        else:
                            st.warning("âš ï¸ ç„¡ç¬¦åˆæ¨™æº–çš„æ¬Šè­‰ (è«‹æª¢æŸ¥ Delta æˆ– å¤©æ•¸æ˜¯å¦æ™®éä¸ä½³)")
                    
                    with tab2:
                        bad = result_df[result_df['SOPç‹€æ…‹'] == 'å‰”é™¤']
                        st.markdown(f"### å‰”é™¤ï¼š{len(bad)} æª”")
                        bad_cols = ['æ¬Šè­‰åç¨±', 'æœªé€šéåŸå› '] + [c for c in cols if c not in ['æ¬Šè­‰åç¨±', 'æœªé€šéåŸå› ']]
                        
                        def highlight_fail(val):
                            return 'color: #ff4b4b; font-weight: bold;' 
                        
                        st.dataframe(bad[bad_cols].style.format(fmt).map(highlight_fail, subset=['æœªé€šéåŸå› ']))

import streamlit as st
import pandas as pd
import numpy as np

# --- æ ¸å¿ƒç­–ç•¥ï¼šè‚¡æ³°æµ SOP åš´æ ¼ç¯©é¸å™¨ ---
class GuTaiSOPAnalyzer:
    def __init__(self):
        pass

    def analyze(self, df):
        # 1. æ¬„ä½å°æ‡‰èˆ‡è³‡æ–™æ¸…æ´— (ä¿ç•™å¼·å¤§çš„è®€å–èƒ½åŠ›)
        target_map = {
            'æ¬Šè­‰åç¨±': ['æ¬Šè­‰åç¨±'],
            'æ¬Šè­‰ä»£ç¢¼': ['æ¬Šè­‰ä»£ç¢¼'],
            'æ¨™çš„åç¨±': ['æ¨™çš„åç¨±', 'æ¨™çš„è­‰åˆ¸'],
            'æ¨™çš„ä»£ç¢¼': ['æ¨™çš„ä»£ç¢¼'],
            'æ¨™çš„åƒ¹æ ¼': ['æ¨™çš„åƒ¹æ ¼', 'æ¨™çš„è‚¡åƒ¹', 'æ¨™çš„æ”¶ç›¤'],
            'è²·åƒ¹': ['æ¬Šè­‰è²·åƒ¹', 'æœ€ä½³è²·åƒ¹', 'è²·åƒ¹'],
            'è³£åƒ¹': ['æ¬Šè­‰è³£åƒ¹', 'æœ€ä½³è³£åƒ¹', 'è³£åƒ¹'],
            'è²·é‡': ['è²·é€²æ¨è¨ˆé‡', 'è²·å¼µ', 'æœ€ä½³è²·é‡'],
            'è³£é‡': ['è³£å‡ºæ¨è¨ˆé‡', 'è³£å¼µ', 'æœ€ä½³è³£é‡'],
            'å±¥ç´„åƒ¹': ['å±¥ç´„åƒ¹', 'åŸ·è¡Œåƒ¹'],
            'å‰©é¤˜å¤©æ•¸': ['å‰©é¤˜å¤©æ•¸', 'è·åˆ°æœŸæ—¥', 'å¤©æ•¸'],
            'æµé€šå¼µæ•¸': ['æµé€šåœ¨å¤–ä¼°è¨ˆå¼µæ•¸', 'æµé€šåœ¨å¤–å¼µæ•¸', 'æœ€æ–°æµé€šåœ¨å¤–å¼µæ•¸', 'å¤–æµå¼µæ•¸'],
            'ç™¼è¡Œå¼µæ•¸': ['ç™¼è¡Œé‡', 'ç™¼è¡Œå¼µæ•¸'],
            'éš±å«æ³¢å‹•ç‡': ['éš±å«æ³¢å‹•ç‡', 'BIV', 'å§”è²·éš±å«æ³¢å‹•ç‡', 'è²·é€²IV'],
            'æ­·å²æ³¢å‹•ç‡': ['æ¨™çš„20æ—¥æ³¢å‹•ç‡', 'æ­·å²æ³¢å‹•ç‡', 'SV20', '20æ—¥æ³¢å‹•ç‡'],
            'Delta': ['DELTA', 'Delta', 'å°æ²–å€¼'],
            'Gamma': ['GAMMA', 'Gamma'],
            'Theta': ['THETA', 'Theta']
        }

        df_clean = pd.DataFrame()
        
        # é–å®šæ¬„ä½
        for target, keywords in target_map.items():
            best_match = None
            for kw in keywords:
                matches = [c for c in df.columns if kw in c]
                if matches:
                    best_match = matches[0]
                    break
            
            if best_match:
                df_clean[target] = df[best_match]
            else:
                # è‹¥ç¼ºæ¬„ä½çµ¦é è¨­å€¼
                if target in ['æ¬Šè­‰åç¨±', 'æ¬Šè­‰ä»£ç¢¼', 'æ¨™çš„åç¨±']:
                    df_clean[target] = ''
                else:
                    df_clean[target] = 0

        # è½‰æ•¸å€¼
        numeric_cols = ['è²·åƒ¹', 'è³£åƒ¹', 'è²·é‡', 'è³£é‡', 'å±¥ç´„åƒ¹', 'å‰©é¤˜å¤©æ•¸', 'æ¨™çš„åƒ¹æ ¼', 
                        'æµé€šå¼µæ•¸', 'ç™¼è¡Œå¼µæ•¸', 'éš±å«æ³¢å‹•ç‡', 'æ­·å²æ³¢å‹•ç‡', 'Delta', 'Gamma', 'Theta']
        
        for col in numeric_cols:
            if col in df_clean.columns:
                df_clean[col] = df_clean[col].astype(str).str.replace('%', '', regex=False).str.replace(',', '', regex=False)
                df_clean[col] = pd.to_numeric(df_clean[col], errors='coerce').fillna(0)

        # ---------------------------------------------------------
        # 2. è¨ˆç®—é—œéµæŒ‡æ¨™ (å°æ‡‰è¡¨ä¸‰ï¼šé¿é›·æŒ‡å—)
        # ---------------------------------------------------------
        
        # A. åƒ¹å·®æ¯” (Spread) -> é¿å…ã€Œåƒ¹å·®éå¤§ã€
        # å…¬å¼: (è³£åƒ¹ - è²·åƒ¹) / è²·åƒ¹
        df_clean['åƒ¹å·®æ¯”'] = np.where(df_clean['è²·åƒ¹'] > 0, 
                                     (df_clean['è³£åƒ¹'] - df_clean['è²·åƒ¹']) / df_clean['è²·åƒ¹'] * 100, 
                                     999)
        
        # B. æµé€šæ¯” (Circulation) -> é¿å…ã€Œæµé€šæ¯”éé«˜ã€
        # è‹¥ç™¼è¡Œå¼µæ•¸ç•°å¸¸å°(å¯èƒ½å–®ä½ä¸åŒ)ï¼Œåšé˜²å‘†è™•ç†
        df_clean['æµé€šæ¯”'] = 0.0
        mask_issue = df_clean['ç™¼è¡Œå¼µæ•¸'] > 0
        df_clean.loc[mask_issue, 'æµé€šæ¯”'] = (df_clean.loc[mask_issue, 'æµé€šå¼µæ•¸'] / df_clean.loc[mask_issue, 'ç™¼è¡Œå¼µæ•¸']) * 100
        
        # C. æ³¢å‹•ç‡æ ¡æ­£ (çµ±ä¸€å–®ä½ç‚ºå°æ•¸é»ï¼Œå¦‚ 0.45)
        # å¦‚æœ IV > 1 (å¦‚ 45)ï¼Œé™¤ä»¥ 100
        mask_iv = df_clean['éš±å«æ³¢å‹•ç‡'] > 2
        df_clean.loc[mask_iv, 'éš±å«æ³¢å‹•ç‡'] = df_clean.loc[mask_iv, 'éš±å«æ³¢å‹•ç‡'] / 100
        mask_hv = df_clean['æ­·å²æ³¢å‹•ç‡'] > 2
        df_clean.loc[mask_hv, 'æ­·å²æ³¢å‹•ç‡'] = df_clean.loc[mask_hv, 'æ­·å²æ³¢å‹•ç‡'] / 100

        # D. åƒ¹å…§å¤–ç¨‹åº¦ (Moneyness)
        # èªè³¼(Call): (è‚¡åƒ¹ - å±¥ç´„åƒ¹) / å±¥ç´„åƒ¹
        df_clean['åƒ¹å…§å¤–'] = (df_clean['æ¨™çš„åƒ¹æ ¼'] - df_clean['å±¥ç´„åƒ¹']) / df_clean['å±¥ç´„åƒ¹']


        # ---------------------------------------------------------
        # 3. è‚¡æ³°æµ SOP åš´æ ¼ç¯©é¸é‚è¼¯ (å°æ‡‰è¡¨ä¸€ã€è¡¨äºŒ)
        # ---------------------------------------------------------
        
        # æˆ‘å€‘ä¸æ‰“åˆ†äº†ï¼Œç›´æ¥çµ¦ã€Œé€šéã€æˆ–ã€Œå¤±æ•—åŸå› ã€
        df_clean['SOPç‹€æ…‹'] = 'é€šé'
        df_clean['æœªé€šéåŸå› '] = ''
        
        def add_fail_reason(mask, reason):
            # å¦‚æœå·²ç¶“æœ‰åŸå› äº†ï¼Œå°±åŠ é€—è™Ÿä¸²æ¥
            df_clean.loc[mask, 'æœªé€šéåŸå› '] = np.where(
                df_clean.loc[mask, 'æœªé€šéåŸå› '] == '',
                reason,
                df_clean.loc[mask, 'æœªé€šéåŸå› '] + ', ' + reason
            )
            df_clean.loc[mask, 'SOPç‹€æ…‹'] = 'å‰”é™¤'

        # --- è¦å‰‡ 1: å‰©é¤˜å¤©æ•¸ (è¡¨ä¸€ Step 3) ---
        # æ¨™æº–: > 60 å¤©ã€‚ (<30å¤©çµ•å°ä¸ç¢°)
        add_fail_reason(df_clean['å‰©é¤˜å¤©æ•¸'] < 60, 'å¤©æ•¸éçŸ­')
        
        # --- è¦å‰‡ 2: åƒ¹å…§å¤–èˆ‡ Delta (è¡¨äºŒ Key Metrics) ---
        # æ¨™æº–: Delta 0.4 ~ 0.6 (æœ€ä½³)ï¼Œæˆ– åƒ¹å¤–15%~åƒ¹å…§5%
        # å„ªå…ˆçœ‹ Delta
        has_delta = df_clean['Delta'].abs().sum() > 0
        if has_delta:
            # å–çµ•å°å€¼(é˜²èªå”®)
            abs_delta = df_clean['Delta'].abs()
            # æ”¾å¯¬ä¸€é»é»å®¹è¨±å€¼ (0.35~0.65) ä»¥å…ç¯©å¤ªåš´ï¼Œä½†åœ¨é¡¯ç¤ºæ™‚æ¨™è¨»
            add_fail_reason((abs_delta < 0.35) | (abs_delta > 0.65), 'Deltaä¸ä½³')
        else:
            # æ²’ Delta å°±çœ‹åƒ¹å…§å¤–
            sweet_zone = (df_clean['åƒ¹å…§å¤–'] >= -0.15) & (df_clean['åƒ¹å…§å¤–'] <= 0.05)
            add_fail_reason(~sweet_zone, 'éé»ƒé‡‘å€é–“')

        # --- è¦å‰‡ 3: æµé€šæ¯” (è¡¨ä¸‰ é¿é›·) ---
        # æ¨™æº–: > 80% çµ•å°ä¸ç¢° (é€™è£¡è¨­ 70% é è­¦)
        add_fail_reason(df_clean['æµé€šæ¯”'] > 80, 'é«˜æµé€šåœ°é›·')
        
        # --- è¦å‰‡ 4: åƒ¹å·®èˆ‡é€ å¸‚ (è¡¨ä¸‰ å ±åƒ¹å¤±éˆ) ---
        # æ¨™æº–: åƒ¹å·®æ¯” < 2.5% ä¸” å¿…é ˆæœ‰è³£å–®
        add_fail_reason(df_clean['è³£åƒ¹'] == 0, 'ç„¡è³£å–®')
        add_fail_reason(df_clean['åƒ¹å·®æ¯”'] > 2.5, 'åƒ¹å·®éå¤§')
        add_fail_reason((df_clean['è²·é‡']<5) | (df_clean['è³£é‡']<5), 'æ›å–®ä¸è¶³')

        # --- è¦å‰‡ 5: éš±æ³¢é™·é˜± (è¡¨ä¸‰) ---
        # æ¨™æº–: IV ä¸å¯é å¤§æ–¼ HV (è²·è²´äº†)
        # å®¹è¨± IV <= HV + 5% (çµ¦åˆ¸å•†è³ºä¸€é»)
        # ç¢ºä¿æœ‰æ•¸æ“šæ‰æ¯”
        has_vol = (df_clean['æ­·å²æ³¢å‹•ç‡'] > 0) & (df_clean['éš±å«æ³¢å‹•ç‡'] > 0)
        # åˆ¤æ–·éè²´: IV > HV + 0.05 (5%)
        is_expensive = has_vol & (df_clean['éš±å«æ³¢å‹•ç‡'] > (df_clean['æ­·å²æ³¢å‹•ç‡'] + 0.08)) 
        add_fail_reason(is_expensive, 'éš±æ³¢å¤ªè²´')

        # ---------------------------------------------------------
        # 4. æ’åºèˆ‡åˆ†é¡
        # ---------------------------------------------------------
        # æ’åºé‚è¼¯ï¼šé€šéçš„æ”¾å‰é¢ï¼Œç„¶å¾Œä¾ç…§ Spread å° -> å¤§æ’åº
        df_clean['æ’åºæ¬Šé‡'] = df_clean['åƒ¹å·®æ¯”']
        # æ²’é€šéçš„ä¸Ÿåˆ°å¾Œé¢
        df_clean.loc[df_clean['SOPç‹€æ…‹'] == 'å‰”é™¤', 'æ’åºæ¬Šé‡'] += 1000
        
        return df_clean.sort_values(by='æ’åºæ¬Šé‡'), None

# --- æª”æ¡ˆè®€å– (ç¶­æŒå¼·å¤§çš„é›™æ¨™é¡Œè™•ç†) ---
def load_data_robust(file):
    filename = file.name.lower()
    try:
        if filename.endswith(('.xls', '.xlsx')):
            df_raw = pd.read_excel(file, header=None)
        else:
            try:
                df_raw = pd.read_csv(file, header=None, encoding='utf-8-sig')
            except:
                file.seek(0)
                df_raw = pd.read_csv(file, header=None, encoding='big5')
    except Exception as e:
        return None, f"æª”æ¡ˆè®€å–å¤±æ•—: {e}"

    # æ‰¾æ¨™é¡Œåˆ— (ä»£ç¢¼ + åç¨±)
    header_idx = -1
    for i, row in df_raw.head(20).iterrows():
        row_str = " ".join(row.astype(str).values)
        if 'ä»£ç¢¼' in row_str and 'åç¨±' in row_str:
            header_idx = i
            break
    
    if header_idx == -1: return None, "æ‰¾ä¸åˆ°æ¨™é¡Œåˆ—"

    # è™•ç†é›™å±¤æ¨™é¡Œ
    new_columns = []
    if header_idx > 0:
        row_upper = df_raw.iloc[header_idx - 1].fillna('').astype(str)
        row_lower = df_raw.iloc[header_idx].fillna('').astype(str)
        if 'æ¨™çš„' in row_upper.values or 'æ¬Šè­‰' in row_upper.values:
            for up, low in zip(row_upper, row_lower):
                up, low = up.strip(), low.strip()
                new_columns.append(f"{up}{low}" if up and up!=low else low)
        else:
            new_columns = row_lower.tolist()
    else:
        new_columns = df_raw.iloc[header_idx].fillna('').astype(str).tolist()

    # é™¤é‡
    seen = {}
    deduped = []
    for col in new_columns:
        col = col.replace(' ', '').replace('\n', '')
        if col in seen: seen[col] += 1; deduped.append(f"{col}_{seen[col]}")
        else: seen[col] = 0; deduped.append(col)

    df = df_raw.iloc[header_idx + 1:].copy()
    df.columns = deduped
    return df, None

# --- Streamlit ç¶²é ä»‹é¢ ---
st.set_page_config(page_title="è‚¡æ³°æµæ¬Šè­‰SOP", layout="wide")

st.title("ğŸ›¡ï¸ è‚¡æ³°æµ-æ¬Šè­‰ SOP åš´æ ¼ç¯©é¸å™¨")
st.markdown("""
æœ¬å·¥å…·ä¾ç…§ **ã€Œè‚¡æ³°æµ SOP è¡¨æ ¼ã€** é€²è¡Œåš´æ ¼æŠŠé—œã€‚
- **âœ… åš´é¸å€**ï¼šç¬¦åˆ Delta 0.4~0.6ã€å¤©æ•¸>60ã€ä½æµé€šã€ä½åƒ¹å·®çš„æ‰€æœ‰æ¢ä»¶ã€‚
- **âŒ å‰”é™¤å€**ï¼šåªè¦é•åä»»ä½•ä¸€é …ã€Œé¿é›·æŒ‡å—ã€ï¼Œç›´æ¥å‰”é™¤ä¸¦å‘ŠçŸ¥åŸå› ã€‚
""")

uploaded_file = st.file_uploader("ğŸ“‚ ä¸Šå‚³æ¬Šè­‰å ±è¡¨ (Excel/CSV)", type=['csv', 'xls', 'xlsx'])

if uploaded_file is not None:
    df, error = load_data_robust(uploaded_file)
    
    if error:
        st.error(error)
    else:
        # æ¨™çš„é¸æ“‡
        target_col = next((c for c in df.columns if 'æ¨™çš„åç¨±' in c), None)
        if not target_col: target_col = next((c for c in df.columns if 'æ¨™çš„ä»£ç¢¼' in c), None)

        if not target_col:
            st.error("âŒ æ‰¾ä¸åˆ°æ¨™çš„åç¨±/ä»£ç¢¼æ¬„ä½")
        else:
            with st.sidebar:
                st.header("1ï¸âƒ£ æ¨™çš„ç¯©é¸")
                df[target_col] = df[target_col].astype(str).str.strip()
                stock_list = sorted([x for x in df[target_col].unique() if x.lower() != 'nan' and x != ''])
                selected_stock = st.selectbox("æœå°‹æ¨™çš„:", stock_list)
                
                df_filtered = df[df[target_col] == selected_stock].copy()
                
                # é¡¯ç¤ºæ¯è‚¡åƒ¹æ ¼
                current_price = 0
                price_col = next((c for c in df_filtered.columns if 'æ¨™çš„åƒ¹æ ¼' in c), None)
                if price_col:
                    try:
                        current_price = pd.to_numeric(df_filtered[price_col], errors='coerce').iloc[0]
                        st.metric("æ¯è‚¡åƒ¹æ ¼", f"{current_price:.2f}")
                    except: pass
                
                st.markdown("---")
                st.header("ğŸ’° è³‡é‡‘æ§ç®¡è©¦ç®—")
                total_capital = st.number_input("æ‚¨çš„ç¸½è³‡é‡‘ (è¬)", value=100, step=10)
                warrant_allocation = total_capital * 0.15
                st.info(f"ä¾æ“š SOPï¼Œæ¬Šè­‰éƒ¨ä½å»ºè­°ä¸Šé™ï¼š\n**{warrant_allocation:.1f} è¬** (15%)")
                st.caption("âš ï¸ æ¬Šè­‰æ˜¯è€—æï¼Œçµ•ä¸å‡¹å–®ï¼Œä¸åšé•·æœŸæŒæœ‰")

            # åŸ·è¡Œåˆ†æ
            if not df_filtered.empty:
                analyzer = GuTaiSOPAnalyzer()
                result_df, err = analyzer.analyze(df_filtered)
                
                if err:
                    st.error(err)
                else:
                    # é¡¯ç¤ºæ¬„ä½
                    cols = ['æ¬Šè­‰åç¨±', 'æœªé€šéåŸå› ', 'Delta', 'å‰©é¤˜å¤©æ•¸', 'åƒ¹å·®æ¯”', 'æµé€šæ¯”', 
                            'è²·åƒ¹', 'è³£åƒ¹', 'éš±å«æ³¢å‹•ç‡', 'æ­·å²æ³¢å‹•ç‡', 'Gamma']
                    
                    # æ ¼å¼
                    fmt = {
                        'Delta': '{:.2f}', 'Gamma': '{:.3f}', 
                        'åƒ¹å·®æ¯”': '{:.2f}%', 'æµé€šæ¯”': '{:.1f}%',
                        'éš±å«æ³¢å‹•ç‡': '{:.2f}', 'æ­·å²æ³¢å‹•ç‡': '{:.2f}', 
                        'è²·åƒ¹': '{:.2f}', 'è³£åƒ¹': '{:.2f}'
                    }

                    # åˆ†é 
                    tab1, tab2 = st.tabs(["âœ… è‚¡æ³°åš´é¸ (SOP Pass)", "âŒ å‰”é™¤å€ (Fail)"])
                    
                    with tab1:
                        good = result_df[result_df['SOPç‹€æ…‹'] == 'é€šé']
                        st.markdown(f"### ç¬¦åˆæ¨™æº–ï¼š{len(good)} æª”")
                        if not good.empty:
                            # é‡å°åš´é¸åå–®ï¼Œä¸é¡¯ç¤ºã€Œæœªé€šéåŸå› ã€æ¬„ä½
                            clean_cols = [c for c in cols if c != 'æœªé€šéåŸå› ']
                            st.dataframe(good[clean_cols].style.format(fmt))
                            st.success("ğŸ‰ é€™äº›æ¬Šè­‰é€šéäº†æ‰€æœ‰ SOP æª¢æ ¸ï¼š\n- Delta 0.4~0.6 (é»ƒé‡‘å€é–“)\n- å¤©æ•¸ > 60å¤©\n- åƒ¹å·®åˆç†ã€ç±Œç¢¼å®‰å®š")
                        else:
                            st.warning("âš ï¸ æ­¤æ¨™çš„ç›®å‰æ²’æœ‰æ¬Šè­‰é€šéã€Œè‚¡æ³°æµåš´æ ¼ SOPã€ã€‚å»ºè­°ç©ºæ‰‹æˆ–æ›è‚¡æ“ä½œã€‚")
                    
                    with tab2:
                        bad = result_df[result_df['SOPç‹€æ…‹'] == 'å‰”é™¤']
                        st.markdown(f"### å‰”é™¤ï¼š{len(bad)} æª”")
                        # å‰”é™¤å€è¦æŠŠã€Œæœªé€šéåŸå› ã€æ”¾åœ¨æœ€å‰é¢
                        bad_cols = ['æ¬Šè­‰åç¨±', 'æœªé€šéåŸå› '] + [c for c in cols if c not in ['æ¬Šè­‰åç¨±', 'æœªé€šéåŸå› ']]
                        
                        def highlight_fail(val):
                            return 'color: #ff4b4b; font-weight: bold;' 
                        
                        st.dataframe(bad[bad_cols].style.format(fmt).map(highlight_fail, subset=['æœªé€šéåŸå› ']))
